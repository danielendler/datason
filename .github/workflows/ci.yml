name: ðŸ§ª CI (Optimized Plugin Testing)

on:
  push:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - 'mkdocs.yml'
      - '.readthedocs.yaml'
  pull_request:
    branches: [ main ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - 'mkdocs.yml'
      - '.readthedocs.yaml'

# Set explicit permissions for security
permissions:
  contents: read
  packages: read
  actions: read

env:
  # Optimize pip for CI
  PIP_CACHE_DIR: ~/.cache/pip
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_INPUT: 1

jobs:
  # Pre-cache base dependencies (runs first, others depend on it)
  cache-base:
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v5

    - name: ðŸ Set up Python 3.11
      uses: actions/setup-python@v6
      with:
        python-version: "3.11"

    - name: ðŸ”‘ Generate cache key
      id: cache-key
      run: |
        echo "key=base-${{ runner.os }}-py3.11-${{ hashFiles('**/pyproject.toml') }}-${{ hashFiles('**/requirements*.txt') }}" >> $GITHUB_OUTPUT

    - name: ðŸ’¾ Cache base Python dependencies
      uses: actions/cache@v4
      id: cache-base-deps
      with:
        path: |
          ~/.cache/pip
          ~/.local/lib/python3.11/site-packages
        key: ${{ steps.cache-key.outputs.key }}
        restore-keys: |
          base-${{ runner.os }}-py3.11-

    - name: ðŸ“¦ Warm cache with base dependencies
      if: steps.cache-base-deps.outputs.cache-hit != 'true'
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install pytest pytest-cov build twine bandit

  # Matrix testing (runs in parallel after base cache is warmed)
  test:
    needs: cache-base
    runs-on: ubuntu-latest
    strategy:
      # Fail-fast strategy: Start fastest + slowest tests first
      fail-fast: false
      max-parallel: 12  # Increased to ensure first batch (minimal + full) starts immediately
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11", "3.12", "3.13"]
        dependency-set:
          # BATCH 1: Start fastest + slowest simultaneously for fail-fast optimization
          - name: "minimal"
            packages: ""
            description: "Core functionality only (no optional dependencies)"
            test-pattern: "tests/unit/"
            cache-extra: ""

          - name: "full"
            packages: ""  # Will use dev dependencies
            description: "All dependencies (full test suite)"
            test-pattern: "tests/unit/ tests/integration/ tests/edge_cases/"
            cache-extra: "dev"
            use-dev: true

          # BATCH 2: Medium-speed tests (start after first batch)
          - name: "with-numpy"
            packages: "numpy"
            description: "Core + NumPy support"
            test-pattern: "tests/unit/ tests/integration/test_ml_serializers.py"
            cache-extra: "numpy"

          - name: "with-pandas"
            packages: "pandas"
            description: "Core + Pandas support"
            test-pattern: "tests/unit/ tests/integration/test_auto_detection_and_metadata.py tests/integration/test_chunked_streaming.py tests/integration/test_template_deserializer.py tests/edge_cases/test_datetime_coverage_boost.py"
            cache-extra: "pandas"

          - name: "with-ml-deps"
            packages: "numpy pandas scikit-learn torch tensorflow"  # Explicit package list for reliability
            description: "Core + ML dependencies (all frameworks)"
            test-pattern: "tests/unit/ tests/integration/"
            cache-extra: "ml"
            use-ml: true
        exclude:
          # Strategic test distribution for efficiency while maintaining coverage:
          # - Python 3.8: Only minimal tests (core compatibility validation)
          # - Python 3.9-3.10: Minimal + one dependency set each (broader compatibility)
          # - Python 3.11: Full coverage (primary development version)
          # - Python 3.12: Full coverage (latest stable version)
          # - Python 3.13: Minimal tests only (dependency availability lag)

          # Python 3.8 - minimal compatibility only
          - python-version: "3.8"
            dependency-set: {name: "with-numpy"}
          - python-version: "3.8"
            dependency-set: {name: "with-pandas"}
          - python-version: "3.8"
            dependency-set: {name: "with-ml-deps"}
          - python-version: "3.8"
            dependency-set: {name: "full"}

          # Python 3.9 - minimal + pandas (data science focus)
          - python-version: "3.9"
            dependency-set: {name: "with-numpy"}
          - python-version: "3.9"
            dependency-set: {name: "with-ml-deps"}
          - python-version: "3.9"
            dependency-set: {name: "full"}

          # Python 3.10 - minimal + ml-deps (ML focus) - ALLOW ML TESTS
          - python-version: "3.10"
            dependency-set: {name: "with-numpy"}
          - python-version: "3.10"
            dependency-set: {name: "with-pandas"}
          - python-version: "3.10"
            dependency-set: {name: "full"}
          # Remove the exclusion for with-ml-deps on Python 3.10 to allow ML testing

          # Python 3.13 - minimal only (waiting for optional dependency support)
          - python-version: "3.13"
            dependency-set: {name: "with-numpy"}
          - python-version: "3.13"
            dependency-set: {name: "with-pandas"}
          - python-version: "3.13"
            dependency-set: {name: "with-ml-deps"}
          - python-version: "3.13"
            dependency-set: {name: "full"}

    name: "ðŸ§ª ${{ matrix.dependency-set.name }} (Python ${{ matrix.python-version }})"

    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v5

    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}

    # Restore base cache first
    - name: ðŸ’¾ Restore base dependencies cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.local/lib/python${{ matrix.python-version }}/site-packages
        key: base-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          base-${{ runner.os }}-py${{ matrix.python-version }}-

    # Specific cache for this dependency set
    - name: ðŸ’¾ Cache specific dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: deps-${{ runner.os }}-py${{ matrix.python-version }}-${{ matrix.dependency-set.cache-extra }}-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          deps-${{ runner.os }}-py${{ matrix.python-version }}-${{ matrix.dependency-set.cache-extra }}-
          deps-${{ runner.os }}-py${{ matrix.python-version }}-

    - name: ðŸ“¦ Install package and dependencies
      run: |
        python -m pip install --upgrade pip
        # Install package first
        pip install -e .

        # Install test dependencies
        pip install pytest pytest-cov

        # Install specific optional dependencies
        if [ "${{ matrix.dependency-set.use-dev }}" = "true" ]; then
          echo "Installing full development environment with all dependencies..."
          # Install core ML dependencies first to avoid conflicts
          pip install numpy pandas scikit-learn scipy || echo "Basic ML deps failed, continuing..."
          pip install torch --index-url https://download.pytorch.org/whl/cpu || echo "PyTorch failed, continuing..."
          pip install tensorflow-cpu || echo "TensorFlow failed, continuing..."
          pip install Pillow catboost optuna plotly polars || echo "Additional ML deps failed, continuing..."

          # Install the package with dev and core ML dependencies (avoiding problematic ones)
          pip install -e ".[dev,ml]" || echo "Dev/ml group install had issues, but continuing..."

          # Try to install problematic packages separately (optional)
          pip install jax[cpu] || echo "JAX failed, skipping..."
          pip install transformers || echo "Transformers failed, skipping..."
          pip install keras || echo "Keras failed, skipping..."
        elif [ "${{ matrix.dependency-set.use-ml }}" = "true" ]; then
          # Install ML dependencies with explicit package list for reliability
          echo "Installing ML dependencies..."
          pip install numpy pandas scikit-learn || echo "Basic ML deps failed, continuing..."
          pip install torch --index-url https://download.pytorch.org/whl/cpu || echo "PyTorch failed, continuing..."
          pip install tensorflow-cpu || echo "TensorFlow failed, continuing..."
          pip install catboost keras optuna plotly polars || echo "Additional ML deps failed, continuing..."
          # Also try the ml group as fallback
          pip install -e ".[ml]" || echo "ML group install failed, continuing with installed packages..."
        elif [ -n "${{ matrix.dependency-set.packages }}" ]; then
          pip install ${{ matrix.dependency-set.packages }}
        fi

    - name: ðŸ“‹ Show installed packages (for debugging)
      run: pip list

    - name: ðŸ§ª Test package import
      run: |
        python -c "
        import datason
        print('âœ… Package imports successfully')
        data = {'test': 123, 'nested': {'value': 'hello'}}
        result = datason.serialize(data)
        print('âœ… Basic serialization works:', result)
        "

    - name: ðŸ”¬ Test ML dependencies (if ML or full job)
      if: matrix.dependency-set.use-ml == true || matrix.dependency-set.use-dev == true
      run: |
        python -c "
        import sys
        print('ðŸ”¬ Testing ML library availability:')

        # Test core ML libraries
        try:
            import numpy as np
            print('âœ… NumPy:', np.__version__)
        except ImportError:
            print('âŒ NumPy: Not available')

        try:
            import pandas as pd
            print('âœ… Pandas:', pd.__version__)
        except ImportError:
            print('âŒ Pandas: Not available')

        try:
            from sklearn.linear_model import LogisticRegression
            print('âœ… Scikit-learn: Available')
        except ImportError:
            print('âŒ Scikit-learn: Not available')

        try:
            import torch
            print('âœ… PyTorch:', torch.__version__)
        except ImportError:
            print('âŒ PyTorch: Not available')

        try:
            import tensorflow as tf
            print('âœ… TensorFlow:', tf.__version__)
        except ImportError:
            print('âŒ TensorFlow: Not available')

        # Test datason ML functionality
        try:
            from datason.ml_serializers import get_ml_library_info
            ml_info = get_ml_library_info()
            available_libs = [k for k, v in ml_info.items() if v]
            print(f'ðŸŽ¯ Available ML libraries for datason: {available_libs}')
        except Exception as e:
            print(f'âŒ ML library detection failed: {e}')
        "

    - name: ðŸ§ª Run tests
      run: |
        # Add test isolation for better reliability
        export PYTHONDONTWRITEBYTECODE=1
        export PYTHONOVERSAFE=1

        # Only run Supported Types Matrix test in ML/full environments
        if [ "${{ matrix.dependency-set.use-ml }}" = "true" ] || [ "${{ matrix.dependency-set.use-dev }}" = "true" ]; then
          export RUN_SUPPORTED_TYPES=1
        fi

        pytest ${{ matrix.dependency-set.test-pattern }} -v \
          --cov=datason \
          --cov-report=xml:coverage-${{ matrix.dependency-set.name }}.xml \
          --cov-report=term-missing \
          --junitxml=junit-${{ matrix.dependency-set.name }}.xml \
          --tb=short \
          -x \
          --cache-clear

    - name: ðŸ“Š Upload coverage to Codecov
      uses: codecov/codecov-action@v5
      if: always() && matrix.dependency-set.name == 'full'
      with:
        files: ./coverage-${{ matrix.dependency-set.name }}.xml
        flags: ${{ matrix.dependency-set.name }}
        name: ${{ matrix.dependency-set.name }}-py${{ matrix.python-version }}
        token: ${{ secrets.CODECOV_TOKEN }}
        fail_ci_if_error: false  # Don't fail CI if codecov upload fails
        verbose: true
        # Only upload from full test suite for accurate coverage calculation
        env_vars: OS,PYTHON

    - name: ðŸ“¤ Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.dependency-set.name }}-py${{ matrix.python-version }}
        path: |
          coverage-${{ matrix.dependency-set.name }}.xml
          junit-${{ matrix.dependency-set.name }}.xml

  # Quality checks (runs in parallel with tests)
  quality:
    needs: cache-base
    runs-on: ubuntu-latest
    name: "ðŸ” Code Quality & Security"
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v5

    - name: ðŸ Set up Python 3.11
      uses: actions/setup-python@v6
      with:
        python-version: "3.11"

    - name: ðŸ’¾ Restore base dependencies cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.local/lib/python3.11/site-packages
        key: ${{ needs.cache-base.outputs.cache-key }}

    - name: ðŸ“¦ Install quality tools
      run: |
        python -m pip install --upgrade pip
        pip install -e .  # Install package to ensure dependencies are available
        pip install ruff bandit[toml] mypy

    - name: ðŸŽ¨ Run Ruff linter
      run: |
        echo "ðŸ” Running Ruff linter..."
        ruff check datason/ tests/ examples/ scripts/ --output-format=github

    - name: ðŸŽ¨ Run Ruff formatter check
      run: |
        echo "ðŸŽ¨ Checking code formatting..."
        ruff format --check datason/ tests/ examples/ scripts/

    - name: ðŸ” Type check with mypy
      run: |
        echo "ðŸ” Running type checks..."
        mypy datason/ --install-types --non-interactive || true

    - name: ðŸ”’ Run Bandit security scan
      run: |
        echo "ðŸ”’ Running security scan..."
        bandit -r datason/ -f json -o bandit-report.json || true

    - name: ðŸ“Š Generate Quality & Security Report
      if: always()
      run: |
        echo "## ðŸ” Code Quality & Security Report" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸŽ¨ Ruff Linting" >> $GITHUB_STEP_SUMMARY
        if ruff check datason/ tests/ examples/ scripts/ --output-format=concise > ruff-results.txt 2>&1; then
          echo "âœ… **Linting**: All checks passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Linting**: Issues found" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Show Details</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          head -20 ruff-results.txt >> $GITHUB_STEP_SUMMARY || echo "No detailed output available" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY
        fi

        echo "### ðŸŽ¨ Code Formatting" >> $GITHUB_STEP_SUMMARY
        if ruff format --check --diff datason/ tests/ examples/ scripts/ > format-results.txt 2>&1; then
          echo "âœ… **Formatting**: All files properly formatted" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Formatting**: Issues found" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Show Formatting Diff</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```diff' >> $GITHUB_STEP_SUMMARY
          head -30 format-results.txt >> $GITHUB_STEP_SUMMARY || echo "No detailed output available" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY
        fi

        echo "### ðŸ›¡ï¸ Security Scan Results" >> $GITHUB_STEP_SUMMARY
        if [ -f bandit-report.json ]; then
          python3 -c "
        import json
        try:
            with open('bandit-report.json') as f:
                report = json.load(f)
            metrics = report['metrics']['_totals']
            high = metrics.get('SEVERITY.HIGH', 0)
            medium = metrics.get('SEVERITY.MEDIUM', 0)
            low = metrics.get('SEVERITY.LOW', 0)
            loc = metrics.get('loc', 0)

            print(f'ðŸ“Š **Scanned**: {loc} lines of code')
            if high == 0 and medium == 0:
                print('âœ… **Security**: No critical issues found')
                if low > 0:
                    print(f'â„¹ï¸ **Info**: {low} low severity informational findings')
            else:
                print(f'âš ï¸ **Security**: {high} high, {medium} medium, {low} low severity issues')
        except Exception as e:
            print('âŒ **Security**: Scan report parsing failed')
            print(f'Error: {e}')
        " >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Security**: Report not generated" >> $GITHUB_STEP_SUMMARY
        fi

        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Quality checks completed at $(date)*" >> $GITHUB_STEP_SUMMARY

    - name: ðŸ“¤ Upload security report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-report-py3.11
        path: bandit-report.json

  # Build package (only runs if tests pass - but doesn't wait for ALL tests)
  build:
    needs: [cache-base]
    # Only run if not a draft PR
    if: github.event.pull_request.draft == false || github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v5

    - name: ðŸ Set up Python 3.11
      uses: actions/setup-python@v6
      with:
        python-version: "3.11"

    - name: ðŸ’¾ Restore base dependencies cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.local/lib/python3.11/site-packages
        key: ${{ needs.cache-base.outputs.cache-key }}

    - name: ðŸ“¦ Install build tools
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: ðŸ—ï¸ Build package
      run: python -m build

    - name: âœ… Check package
      run: twine check dist/*

    - name: ðŸ“¤ Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist-py3.11
        path: dist/

  # Summary job (waits for all tests, provides final status)
  test-summary:
    needs: [test, quality, build]
    runs-on: ubuntu-latest
    if: always()
    steps:
    - name: ðŸ“‹ Check test results
      run: |
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.quality.result }}" = "success" ]; then
          echo "âœ… All tests passed!"
          exit 0
        else
          echo "âŒ Some tests failed:"
          echo "  Tests: ${{ needs.test.result }}"
          echo "  Quality: ${{ needs.quality.result }}"
          echo "  Build: ${{ needs.build.result }}"
          exit 1
        fi

  # Python version compatibility check (tests our minimum version claim)
  python-compatibility:
    runs-on: ubuntu-latest
    name: "ðŸ Python Compatibility Check"
    strategy:
      matrix:
        python-version: ["3.8", "3.13"]  # Test minimum and current versions
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v5

    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}

    - name: ðŸ“¦ Install package (minimal)
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: ðŸ§ª Run compatibility test
      run: |
        python scripts/test_python_compatibility.py

    - name: ðŸ“‹ Generate compatibility report
      run: |
        echo "## ðŸ Python ${{ matrix.python-version }} Compatibility Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Test Results:" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        python scripts/test_python_compatibility.py >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
