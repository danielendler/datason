name: 🚀 DataSON PR Performance Benchmark

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'datason/**'
      - 'pyproject.toml'
      - 'setup.py'
      - '*.py'
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number (for manual runs)'
        required: true
        type: string
      benchmark_type:
        description: 'Benchmark type to run'
        required: false
        default: 'pr_optimized'
        type: choice
        options:
        - pr_optimized
        - quick
        - competitive

permissions:
  contents: read
  pull-requests: write

jobs:
  build-datason:
    name: 📦 Build DataSON Package
    runs-on: ubuntu-latest

    outputs:
      artifact-name: ${{ steps.build.outputs.artifact-name }}
      wheel-file: ${{ steps.build.outputs.wheel-file }}

    steps:
    - name: 📥 Checkout DataSON PR
      uses: actions/checkout@v5

    - name: 🐍 Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: 📦 Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel setuptools

    - name: 🔨 Build DataSON wheel
      id: build
      run: |
        # Clean any previous builds
        rm -rf dist/ build/ *.egg-info/

        # Build wheel
        python -m build --wheel

        # Get wheel filename
        WHEEL_FILE=$(ls dist/*.whl | head -n1)
        WHEEL_NAME=$(basename "$WHEEL_FILE")

        echo "wheel-file=$WHEEL_NAME" >> $GITHUB_OUTPUT
        # Handle both pull_request and workflow_dispatch triggers
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          PR_NUM="${{ github.event.number }}"
        else
          PR_NUM="${{ github.event.inputs.pr_number }}"
        fi

        # Use simpler artifact name as expected by datason-benchmarks
        echo "artifact-name=datason-wheel" >> $GITHUB_OUTPUT

        echo "✅ Built wheel: $WHEEL_NAME"
        ls -la dist/

    - name: 📤 Upload DataSON wheel
      uses: actions/upload-artifact@v4
      with:
        name: datason-wheel
        path: dist/*.whl
        retention-days: 7

    - name: 🧪 Quick smoke test
      run: |
        # Install the wheel we just built
        pip install dist/*.whl

        # Basic smoke test
        python -c "
        import datason
        print(f'DataSON {datason.__version__} installed successfully')

        # Test basic functionality
        test_data = {'test': 'value', 'number': 42}
        serialized = datason.serialize(test_data)
        deserialized = datason.deserialize(serialized)
        assert deserialized == test_data
        print('✅ Basic serialization test passed')
        "

  trigger-benchmark:
    name: 🚀 Trigger External Benchmark Suite
    runs-on: ubuntu-latest
    needs: build-datason

    steps:
    - name: 🚀 Trigger datason-benchmarks repository
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.BENCHMARK_REPO_TOKEN }}
        script: |
          console.log('🚀 Triggering benchmark suite in external repository...');

          try {
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: 'danielendler',
              repo: 'datason-benchmarks',
              workflow_id: 'pr-performance-check.yml',
              ref: 'main',
              inputs: {
                pr_number: '${{ github.event_name == 'pull_request' && github.event.number || github.event.inputs.pr_number }}',
                commit_sha: '${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}',
                artifact_name: 'datason-wheel',
                datason_repo: '${{ github.repository }}',
                benchmark_type: '${{ github.event.inputs.benchmark_type || 'pr_optimized' }}'
              }
            });

            console.log('✅ Successfully triggered benchmark workflow');
            console.log(`📊 Benchmark type: ${{ github.event.inputs.benchmark_type || 'pr_optimized' }}`);
            console.log(`📦 Artifact: ${{ needs.build-datason.outputs.artifact-name }}`);
            console.log(`🔗 DataSON repo: ${{ github.repository }}`);

          } catch (error) {
            console.error('❌ Failed to trigger benchmark workflow:', error.message);

            // If the workflow file doesn't exist, provide helpful guidance
            if (error.message.includes('workflow_id')) {
              console.log('');
              console.log('📝 The benchmark repository may need setup. Expected workflow file:');
              console.log('   .github/workflows/pr-performance-check.yml');
              console.log('');
              console.log('🔧 To set up the benchmark repository:');
              console.log('   1. Create the workflow file in datason-benchmarks repository');
              console.log('   2. Ensure it accepts the workflow_dispatch inputs shown above');
              console.log('   3. Verify the BENCHMARK_REPO_TOKEN has workflow permissions');
            }

            throw error;
          }

    - name: ✅ Benchmark trigger complete
      run: |
        echo "✅ Benchmark suite triggered successfully"
        echo "📊 The external datason-benchmarks repository will:"
        echo "   • Download the PR wheel artifact"
        echo "   • Run comprehensive performance tests"
        echo "   • Generate detailed analysis reports"
        echo "   • Post results back to this PR"
        echo ""
        echo "🔍 Monitor progress at:"
        echo "   https://github.com/danielendler/datason-benchmarks/actions"
        echo ""
        echo "📋 Expected workflow: pr-performance-check.yml"
        echo "📦 Artifact name: datason-wheel"
        echo "🎯 Benchmark type: ${{ github.event.inputs.benchmark_type || 'pr_optimized' }}"
